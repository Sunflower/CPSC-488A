{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import math\n",
    "import scipy.sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by exploring academic training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48964"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word_id</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>word_type</th>\n",
       "      <th>function</th>\n",
       "      <th>seg_type</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text_id</th>\n",
       "      <th>text_tag</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25070</td>\n",
       "      <td>25070</td>\n",
       "      <td>HER</td>\n",
       "      <td>she</td>\n",
       "      <td>DPS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1267</td>\n",
       "      <td>a6u-fragment02</td>\n",
       "      <td>a6u</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25071</td>\n",
       "      <td>25071</td>\n",
       "      <td>DRESS</td>\n",
       "      <td>dress</td>\n",
       "      <td>NN1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1267</td>\n",
       "      <td>a6u-fragment02</td>\n",
       "      <td>a6u</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25072</td>\n",
       "      <td>25072</td>\n",
       "      <td>HANGS</td>\n",
       "      <td>hang</td>\n",
       "      <td>VVZ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1267</td>\n",
       "      <td>a6u-fragment02</td>\n",
       "      <td>a6u</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25073</td>\n",
       "      <td>25073</td>\n",
       "      <td>HERE'</td>\n",
       "      <td>here'</td>\n",
       "      <td>NP0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1267</td>\n",
       "      <td>a6u-fragment02</td>\n",
       "      <td>a6u</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25074</td>\n",
       "      <td>25074</td>\n",
       "      <td>DE-FROCKING</td>\n",
       "      <td>de-frock</td>\n",
       "      <td>VVG</td>\n",
       "      <td>mrw</td>\n",
       "      <td>met</td>\n",
       "      <td>1267</td>\n",
       "      <td>a6u-fragment02</td>\n",
       "      <td>a6u</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  word_id         word     lemma word_type function seg_type  \\\n",
       "0  25070       25070    HER          she       DPS                          \n",
       "1  25071       25071    DRESS        dress     NN1                          \n",
       "2  25072       25072    HANGS        hang      VVZ                          \n",
       "3  25073       25073    HERE'        here'     NP0                          \n",
       "4  25074       25074    DE-FROCKING  de-frock  VVG       mrw      met       \n",
       "\n",
       "   sentence_id         text_id text_tag     genre  \n",
       "0  1267         a6u-fragment02  a6u      academic  \n",
       "1  1267         a6u-fragment02  a6u      academic  \n",
       "2  1267         a6u-fragment02  a6u      academic  \n",
       "3  1267         a6u-fragment02  a6u      academic  \n",
       "4  1267         a6u-fragment02  a6u      academic  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = pd.read_csv('data/train/academic/words.csv', encoding='ISO--8859-1', na_filter=False)\n",
    "display(len(all_words))\n",
    "all_words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep only content words and filter stop verbs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping content words: http://ucrel.lancs.ac.uk/bnc2/bnc2guide.htm#m2adv\n",
    "# Does not include forms of 'be', 'do', 'have', or modal verbs,\n",
    "# as suggested in https://github.com/EducationalTestingService/metaphor/tree/master/content-words\n",
    "content_word_pos = set([\n",
    "    'NN1', 'NN2', 'NN0',\n",
    "    'NP0',\n",
    "    'NN1-NP0', 'NN1-VVB', 'NN1-VVG', 'NN2-VVZ',\n",
    "    'NP0-NN1',\n",
    "    'VVB', 'VVD', 'VVG', 'VVI', 'VVN', 'VVZ',\n",
    "    'VVB-NN1', 'VVD-VVN', 'VVD-AJ0', 'VVG-AJ0', 'VVG-NN1', 'VVZ-NN2',\n",
    "    'AJ0', 'AJC', 'AJS',\n",
    "    'AJ0-NN1', 'AJ0-VVG', 'AJ0-VVN',\n",
    "    'AV0', 'AVQ', 'AVP',\n",
    "    'AV0-AJ0'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25360"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word_id</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>word_type</th>\n",
       "      <th>function</th>\n",
       "      <th>seg_type</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text_id</th>\n",
       "      <th>text_tag</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25071</td>\n",
       "      <td>25071</td>\n",
       "      <td>DRESS</td>\n",
       "      <td>dress</td>\n",
       "      <td>NN1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1267</td>\n",
       "      <td>a6u-fragment02</td>\n",
       "      <td>a6u</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25072</td>\n",
       "      <td>25072</td>\n",
       "      <td>HANGS</td>\n",
       "      <td>hang</td>\n",
       "      <td>VVZ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1267</td>\n",
       "      <td>a6u-fragment02</td>\n",
       "      <td>a6u</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25073</td>\n",
       "      <td>25073</td>\n",
       "      <td>HERE'</td>\n",
       "      <td>here'</td>\n",
       "      <td>NP0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1267</td>\n",
       "      <td>a6u-fragment02</td>\n",
       "      <td>a6u</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25074</td>\n",
       "      <td>25074</td>\n",
       "      <td>DE-FROCKING</td>\n",
       "      <td>de-frock</td>\n",
       "      <td>VVG</td>\n",
       "      <td>mrw</td>\n",
       "      <td>met</td>\n",
       "      <td>1267</td>\n",
       "      <td>a6u-fragment02</td>\n",
       "      <td>a6u</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25076</td>\n",
       "      <td>25076</td>\n",
       "      <td>KAHLO</td>\n",
       "      <td>kahlo</td>\n",
       "      <td>NP0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1267</td>\n",
       "      <td>a6u-fragment02</td>\n",
       "      <td>a6u</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25077</td>\n",
       "      <td>25077</td>\n",
       "      <td>CULT</td>\n",
       "      <td>cult</td>\n",
       "      <td>NN1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1267</td>\n",
       "      <td>a6u-fragment02</td>\n",
       "      <td>a6u</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25078</td>\n",
       "      <td>25078</td>\n",
       "      <td>Oriana</td>\n",
       "      <td>oriana</td>\n",
       "      <td>NP0-NN1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1268</td>\n",
       "      <td>a6u-fragment02</td>\n",
       "      <td>a6u</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25079</td>\n",
       "      <td>25079</td>\n",
       "      <td>Baddeley</td>\n",
       "      <td>baddeley</td>\n",
       "      <td>NP0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1268</td>\n",
       "      <td>a6u-fragment02</td>\n",
       "      <td>a6u</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25083</td>\n",
       "      <td>25083</td>\n",
       "      <td>witnessed</td>\n",
       "      <td>witness</td>\n",
       "      <td>VVN</td>\n",
       "      <td>mrw</td>\n",
       "      <td>met</td>\n",
       "      <td>1269</td>\n",
       "      <td>a6u-fragment02</td>\n",
       "      <td>a6u</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>25085</td>\n",
       "      <td>25085</td>\n",
       "      <td>shift</td>\n",
       "      <td>shift</td>\n",
       "      <td>NN1-VVB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1269</td>\n",
       "      <td>a6u-fragment02</td>\n",
       "      <td>a6u</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  word_id         word     lemma word_type function seg_type  \\\n",
       "1   25071       25071    DRESS        dress     NN1                          \n",
       "2   25072       25072    HANGS        hang      VVZ                          \n",
       "3   25073       25073    HERE'        here'     NP0                          \n",
       "4   25074       25074    DE-FROCKING  de-frock  VVG       mrw      met       \n",
       "6   25076       25076    KAHLO        kahlo     NP0                          \n",
       "7   25077       25077    CULT         cult      NN1                          \n",
       "8   25078       25078    Oriana       oriana    NP0-NN1                      \n",
       "9   25079       25079    Baddeley     baddeley  NP0                          \n",
       "13  25083       25083    witnessed    witness   VVN       mrw      met       \n",
       "15  25085       25085    shift        shift     NN1-VVB                      \n",
       "\n",
       "    sentence_id         text_id text_tag     genre  \n",
       "1   1267         a6u-fragment02  a6u      academic  \n",
       "2   1267         a6u-fragment02  a6u      academic  \n",
       "3   1267         a6u-fragment02  a6u      academic  \n",
       "4   1267         a6u-fragment02  a6u      academic  \n",
       "6   1267         a6u-fragment02  a6u      academic  \n",
       "7   1267         a6u-fragment02  a6u      academic  \n",
       "8   1268         a6u-fragment02  a6u      academic  \n",
       "9   1268         a6u-fragment02  a6u      academic  \n",
       "13  1269         a6u-fragment02  a6u      academic  \n",
       "15  1269         a6u-fragment02  a6u      academic  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_words = all_words[all_words['word_type'].isin(content_word_pos)]\n",
    "display(len(content_words))\n",
    "content_words.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparsification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vocabulary using content words. This will be used as the unigram features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7327"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>operated</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jackson</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>underpin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flowerdew</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rennes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patterns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warrant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [operated, Jackson, underpin, Flowerdew, out, Rennes, patterns, warrant, promoted, Code]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = content_words[['word']].drop_duplicates().set_index('word')\n",
    "\n",
    "display(len(vocabulary))\n",
    "vocabulary.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_featurize(words, vocabulary):\n",
    "    print('Build iterable sentences.')\n",
    "    iterable_sentences = words.groupby('sentence_id')['word'].apply(list)\n",
    "    display(len(iterable_sentences))\n",
    "    display(iterable_sentences[:5])\n",
    "\n",
    "    indices = []\n",
    "    data = []\n",
    "    indptr = [0]\n",
    "    for i, word, sentence_id in words[['word', 'sentence_id']].itertuples():\n",
    "        sentence = iterable_sentences[sentence_id]\n",
    "\n",
    "        # Used to generate a row of 0's and 1's for sparse matrix\n",
    "        unique_unigram_indices = set()\n",
    "        for context_word in sentence:\n",
    "            if context_word == word:\n",
    "                continue\n",
    "            unique_unigram_indices.add(vocabulary.index.get_loc(context_word))\n",
    "\n",
    "        # Data = 1 at column index of sparse matrix = row index of word in vocabulary.\n",
    "        indices.extend(unique_unigram_indices)  # Indices of the data values in this row.\n",
    "        data.extend(np.ones(len(unique_unigram_indices), dtype=int))  # Data of all one's.\n",
    "        indptr.append(indptr[-1]+len(unique_unigram_indices))\n",
    "\n",
    "        if not i % 2000:\n",
    "            print('-', end='', flush=True)\n",
    "\n",
    "    return (\n",
    "        csr_matrix((data, indices, indptr), dtype=int, shape=(len(words), len(vocabulary))),\n",
    "        iterable_sentences\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Build iterable sentences.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1961"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_id\n",
       "1267    [DRESS, HANGS, HERE', DE-FROCKING, KAHLO, CULT]                                                                               \n",
       "1268    [Oriana, Baddeley]                                                                                                            \n",
       "1269    [witnessed, shift, art, establishment, attitudes, art, produced, traditional, parameters]                                     \n",
       "1270    [work, previously, marginalised, artists, become, area, rich, speculation, art, dealers, priced, modern, masters, market]     \n",
       "1271    [Almost, year, witnessed, discovery, new, artistic, terrain, graffiti, art, Soviet, art, Australian, art, art, Latin, America]\n",
       "Name: word, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<25360x7327 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 386398 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(25360, 7327)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = content_words\n",
    "sparse_unigram_features, iterable_sentences = sparse_featurize(words, vocabulary)\n",
    "\n",
    "scipy.sparse.save_npz('data/sparse_unigram_features.npz', sparse_unigram_features)\n",
    "display(sparse_unigram_features)\n",
    "sparse_unigram_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect if sparse features are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_unigram_features = scipy.sparse.load_npz('data/sparse_unigram_features.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     25449         \n",
       "word_id        25449         \n",
       "word           passionate    \n",
       "lemma          passionate    \n",
       "word_type      AJ0           \n",
       "function                     \n",
       "seg_type                     \n",
       "sentence_id    1282          \n",
       "text_id        a6u-fragment02\n",
       "text_tag       a6u           \n",
       "genre          academic      \n",
       "Name: 379, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Diego',\n",
       " 'Rivera',\n",
       " 'appearance',\n",
       " 'come',\n",
       " 'dominate',\n",
       " 'emotional',\n",
       " 'flamboyant',\n",
       " 'husband',\n",
       " 'obsession',\n",
       " 'pain',\n",
       " 'passionate',\n",
       " 'physical',\n",
       " 'responses',\n",
       " 'work']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 70,  71, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180,  16])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Diego',\n",
       " 'Rivera',\n",
       " 'appearance',\n",
       " 'come',\n",
       " 'dominate',\n",
       " 'emotional',\n",
       " 'flamboyant',\n",
       " 'husband',\n",
       " 'obsession',\n",
       " 'pain',\n",
       " 'physical',\n",
       " 'responses',\n",
       " 'work']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "select_word_i = 210\n",
    "\n",
    "selected_word = words.iloc[select_word_i]\n",
    "display(selected_word)\n",
    "sentence_of_selected_word = sorted(list(set(iterable_sentences.loc[selected_word.sentence_id])))\n",
    "display(sentence_of_selected_word)\n",
    "\n",
    "unigram_select_indices = np.nonzero(sparse_unigram_features[select_word_i])[:50][1]  # Nonzero indices indicating word.\n",
    "display(unigram_select_indices)\n",
    "sparse_matrix_sentence_selections = sorted(list(vocabulary.iloc[unigram_select_indices].index))\n",
    "display(sparse_matrix_sentence_selections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30545"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "26579    False\n",
       "38668    True \n",
       "2617     True \n",
       "38976    False\n",
       "12019    False\n",
       "16848    False\n",
       "42138    False\n",
       "40767    False\n",
       "58870    True \n",
       "24636    False\n",
       "Name: function, dtype: bool"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>word_type</th>\n",
       "      <th>function</th>\n",
       "      <th>seg_type</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text_id</th>\n",
       "      <th>text_types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25074</td>\n",
       "      <td>DE-FROCKING</td>\n",
       "      <td>de-frock</td>\n",
       "      <td>VVG</td>\n",
       "      <td>mrw</td>\n",
       "      <td>met</td>\n",
       "      <td>1267</td>\n",
       "      <td>a6u-fragment02</td>\n",
       "      <td>a6u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25083</td>\n",
       "      <td>witnessed</td>\n",
       "      <td>witness</td>\n",
       "      <td>VVN</td>\n",
       "      <td>mrw</td>\n",
       "      <td>met</td>\n",
       "      <td>1269</td>\n",
       "      <td>a6u-fragment02</td>\n",
       "      <td>a6u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25090</td>\n",
       "      <td>attitudes</td>\n",
       "      <td>attitude</td>\n",
       "      <td>NN2</td>\n",
       "      <td>mrw</td>\n",
       "      <td>met</td>\n",
       "      <td>1269</td>\n",
       "      <td>a6u-fragment02</td>\n",
       "      <td>a6u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>25107</td>\n",
       "      <td>area</td>\n",
       "      <td>area</td>\n",
       "      <td>NN1</td>\n",
       "      <td>mrw</td>\n",
       "      <td>met</td>\n",
       "      <td>1270</td>\n",
       "      <td>a6u-fragment02</td>\n",
       "      <td>a6u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>25109</td>\n",
       "      <td>rich</td>\n",
       "      <td>rich</td>\n",
       "      <td>AJ0</td>\n",
       "      <td>mrw</td>\n",
       "      <td>met</td>\n",
       "      <td>1270</td>\n",
       "      <td>a6u-fragment02</td>\n",
       "      <td>a6u</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word_id         word     lemma word_type function seg_type  sentence_id  \\\n",
       "4   25074    DE-FROCKING  de-frock  VVG       mrw      met      1267          \n",
       "13  25083    witnessed    witness   VVN       mrw      met      1269          \n",
       "20  25090    attitudes    attitude  NN2       mrw      met      1269          \n",
       "37  25107    area         area      NN1       mrw      met      1270          \n",
       "39  25109    rich         rich      AJ0       mrw      met      1270          \n",
       "\n",
       "           text_id text_types  \n",
       "4   a6u-fragment02  a6u        \n",
       "13  a6u-fragment02  a6u        \n",
       "20  a6u-fragment02  a6u        \n",
       "37  a6u-fragment02  a6u        \n",
       "39  a6u-fragment02  a6u        "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = words['function'] == 'mrw'\n",
    "display(len(labels))\n",
    "display(labels.sample(10))\n",
    "words[labels].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15252905549189721"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(labels)/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30545x8329 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 460517 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = shuffle(sparse_unigram_features, labels, random_state=0)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(verbose=10, random_state=0, C=10, penalty='l1',\n",
    "                         solver='liblinear', class_weight='balanced', max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters = {'C':[1, 5, 10, 20, 100], 'penalty':['l1', 'l2']}\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# clf = GridSearchCV(LogisticRegression(class_weight='balanced', verbose=10), hyperparameters,\n",
    "#                                       verbose=10, cv=10, scoring='f1')\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[LibLinear][CV]  , accuracy=0.8693944353518822, precision=0.5607985480943739, recall=0.6630901287553648, f1=0.6076696165191741, total=   9.9s\n",
      "[CV]  ................................................................\n",
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  , accuracy=0.872013093289689, precision=0.5688073394495413, recall=0.6652360515021459, f1=0.6132542037586548, total=   7.9s\n",
      "[CV]  ................................................................\n",
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   18.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  , accuracy=0.8648117839607201, precision=0.5454545454545454, recall=0.6824034334763949, f1=0.6062917063870352, total=   7.2s\n",
      "[CV]  ................................................................\n",
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   25.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  , accuracy=0.8628477905073649, precision=0.5435992578849722, recall=0.628755364806867, f1=0.5830845771144278, total=   4.8s\n",
      "[CV]  ................................................................\n",
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   30.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  , accuracy=0.8677577741407528, precision=0.5607843137254902, recall=0.6137339055793991, f1=0.5860655737704917, total=   4.9s\n",
      "[CV]  ................................................................\n",
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   35.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  , accuracy=0.8664484451718494, precision=0.5516014234875445, recall=0.6652360515021459, f1=0.603112840466926, total=   4.5s\n",
      "[CV]  ................................................................\n",
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   40.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  , accuracy=0.8650949574328749, precision=0.5490909090909091, recall=0.648068669527897, f1=0.594488188976378, total=   5.1s\n",
      "[CV]  ................................................................\n",
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   45.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  , accuracy=0.8755730189914865, precision=0.5817490494296578, recall=0.6566523605150214, f1=0.6169354838709677, total=   5.0s\n",
      "[CV]  ................................................................\n",
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   50.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  , accuracy=0.8654223968565815, precision=0.5491949910554562, recall=0.6587982832618026, f1=0.5990243902439025, total=   4.1s\n",
      "[CV]  ................................................................\n",
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   54.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  , accuracy=0.860792662954471, precision=0.5332225913621262, recall=0.6903225806451613, f1=0.6016869728209934, total=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   59.1s finished\n"
     ]
    }
   ],
   "source": [
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = cross_validate(clf, scoring=scoring, X=X, y=y, cv=10, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=500,\n",
       "          multi_class='warn', n_jobs=None, penalty='l1', random_state=0,\n",
       "          solver='liblinear', tol=0.0001, verbose=10, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ezutp\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\ezutp\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\ezutp\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\ezutp\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([9.99348378, 8.00513864, 7.31442618, 4.92084098, 4.95672727,\n",
       "        4.58477211, 5.24496722, 5.07560992, 4.16706419, 4.43465042]),\n",
       " 'score_time': array([0.01197028, 0.00997376, 0.00602484, 0.00797224, 0.00598478,\n",
       "        0.00498891, 0.00502777, 0.00698352, 0.00698185, 0.00702095]),\n",
       " 'test_accuracy': array([0.86939444, 0.87201309, 0.86481178, 0.86284779, 0.86775777,\n",
       "        0.86644845, 0.86509496, 0.87557302, 0.8654224 , 0.86079266]),\n",
       " 'train_accuracy': array([0.96991633, 0.96722445, 0.96762459, 0.96995271, 0.96755184,\n",
       "        0.96784285, 0.96744389, 0.96744389, 0.96999018, 0.96857268]),\n",
       " 'test_precision': array([0.56079855, 0.56880734, 0.54545455, 0.54359926, 0.56078431,\n",
       "        0.55160142, 0.54909091, 0.58174905, 0.54919499, 0.53322259]),\n",
       " 'train_precision': array([0.83958838, 0.82762739, 0.82931206, 0.84030726, 0.82911266,\n",
       "        0.83109866, 0.82861698, 0.82901038, 0.84006462, 0.83326661]),\n",
       " 'test_recall': array([0.66309013, 0.66523605, 0.68240343, 0.62875536, 0.61373391,\n",
       "        0.66523605, 0.64806867, 0.65665236, 0.65879828, 0.69032258]),\n",
       " 'train_recall': array([0.99236823, 0.99165275, 0.99189125, 0.99141426, 0.99165275,\n",
       "        0.99046029, 0.99165275, 0.99093728, 0.99212974, 0.99260849]),\n",
       " 'test_f1': array([0.60766962, 0.6132542 , 0.60629171, 0.58308458, 0.58606557,\n",
       "        0.60311284, 0.59448819, 0.61693548, 0.59902439, 0.60168697]),\n",
       " 'train_f1': array([0.90960761, 0.90224585, 0.90334492, 0.90962801, 0.90312772,\n",
       "        0.90380849, 0.90283357, 0.90277023, 0.90978677, 0.90598477])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6011613553928952"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(scores['test_f1']/len(scores['test_f1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.96      0.98     25886\n",
      "        True       0.82      0.99      0.90      4659\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     30545\n",
      "   macro avg       0.91      0.98      0.94     30545\n",
      "weighted avg       0.97      0.97      0.97     30545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf.predict(X)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y, clf.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
